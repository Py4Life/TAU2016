{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Py4Life](https://raw.githubusercontent.com/Py4Life/TAU2015/gh-pages/img/Py4Life-logo-small.png)](http://py4life.github.io/TAU2016/)\n",
    "\n",
    "## Lecture 8 - 18.4.2016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previously\n",
    "\n",
    "- BioPython\n",
    "- Sequence analysis\n",
    "- Sequence data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today\n",
    "\n",
    "#### Topics \n",
    "\n",
    "- Data analysis\n",
    "- Summary statistics\n",
    "- Data visualization\n",
    "\n",
    "#### Packages\n",
    "\n",
    "- [NumPy](http://www.numpy.org/) is the fundamental package for scientific computing with Python. It contains arrays, math functions, linear algebra, random number capabilities and much more.\n",
    "- [Matplotlib](http://matplotlib.org/) is a plotting library which produces publication quality figures\n",
    "- [Pandas](pandas.pydata.org) provides high-performance, easy-to-use data structures and data analysis tools.\n",
    "- [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) is a visualization library based on _matplotlib_ that provides a high-level interface for plotting attractive statistical figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install Numpy\n",
    "!pip install Matplotlib\n",
    "!pip install Pandas\n",
    "!pip install Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Patient Data\n",
    "\n",
    "We are studying inflammation in patients who have been given a new treatment for arthritis, and need to analyze the first dozen data sets. The data sets are stored in comma-separated values (CSV) format: each row holds information for a single patient, and the columns represent successive days. The first few rows of our data file look like this:\n",
    "\n",
    "> 0,0,1,3,1,2,4,7,8,3,3,3,10,5,7,4,7,7,12,18,6,13,11,11,7,7,4,6,8,8,4,4,5,7,3,4,2,3,0,0\n",
    "0,1,2,1,2,1,3,2,2,6,10,11,5,9,4,4,7,16,8,6,18,4,12,5,12,7,11,5,11,3,3,5,4,4,5,5,1,1,0,1\n",
    "0,1,1,3,3,2,6,2,5,9,5,7,4,5,4,15,5,11,9,10,19,14,12,17,7,12,11,7,4,2,10,5,4,2,2,3,2,2,1,1\n",
    "0,0,2,0,4,2,2,1,6,7,10,7,9,13,8,8,15,10,10,7,17,4,4,7,6,15,6,4,9,11,3,5,6,3,3,4,2,3,2,1\n",
    "0,1,1,3,3,1,3,5,2,4,4,7,6,5,3,10,8,10,6,17,9,14,9,7,13,9,12,6,7,7,9,6,3,2,2,4,2,0,1,1\n",
    "\n",
    "#### Objectives\n",
    "\n",
    "- Load __NumPy__, the basic scientific Python library \n",
    "- Read tabular data from a file into Python.\n",
    "- Select individual values and subsections from data.\n",
    "- Perform operations on arrays of data.\n",
    "- Display simple plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "While a lot of powerful tools are built into Python, even more tools exist in the libraries and packages that are written in Python.\n",
    "\n",
    "In order to load our inflammation data, we need to import a library called __NumPy__.  We could load the data using the __csv__ module, but  you should use NumPy when you want to do things with numbers, especially if you have matrices or tables.\n",
    "\n",
    "We can load _NumPy_ using import. We also load __urllib__ to read the data from the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, we need to copy the file from the web to our local disk. This is done using the `urllib.request.urlretrieve` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = r\"https://raw.githubusercontent.com/swcarpentry/python-novice-inflammation/gh-pages/data/inflammation-01.csv\"\n",
    "fname = \"inflammation-01.csv\"\n",
    "urllib.request.urlretrieve(url, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved the file to the local filesystem. Go to the directory you're working from and take a look at the file.\n",
    "\n",
    "Now we can ask _NumPy_ to read the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(fname, delimiter=',')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `np.loadtxt(...)` is a function call that asks Python to run the function `loadtxt` that belongs to the `numpy` library. This dotted notation is used everywhere in Python to refer to the parts of things as `thing.component` (see: _namespaces_).\n",
    "\n",
    "`numpy.loadtxt` has two parameters: the name of the file we want to read, and the delimiter that separates values on a line. These both need to be character strings (or strings for short), so we put them in quotes.\n",
    "\n",
    "We saved the output of `loadtxt` in the variable `data`. When we `print(data)`, only a few rows and columns are shown (with `...` to omit elements when displaying big arrays). To save space, Python displays numbers as `1.` instead of `1.0` when there's nothing interesting after the decimal point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data\n",
    "\n",
    "Now that our data is in memory, we can start doing things with it. First, let's ask what type of thing data refers to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells us that data currently refers to an N-dimensional array created by the NumPy library. \n",
    "\n",
    "To see its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "n_patients,n_days = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that `data` has 60 rows and 40 columns, which are 60 patients and 40 days. `data.shape` is a member of `data`, i.e., a value that is stored as part of a larger value. We use the same dotted notation for the members of values that we use for the functions in libraries because they have the same part-and-whole relationship.\n",
    "\n",
    "If we want to get a single value from the matrix, we must provide an index in square brackets, just as we do with a `list`, but with as many indices as the number of dimensions in `shape` (two in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"first value in data\",data[0,0])\n",
    "print(\"middle value in data:\", data[30, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `data[30, 20]` may not surprise you, but `data[0, 0]` might. Programming languages like Fortran and MATLAB start counting at 1, because that's what human beings have done for thousands of years. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that's simpler for computers to do. Just like with `list` and `str`, if we have an MÃ—N array in Python, its indices go from 0 to M-1 on the first axis and 0 to N-1 on the second. It takes a bit of getting used to, but one way to remember the rule is that the index is how many steps we have to take from the start to get the item we want.\n",
    "\n",
    "\n",
    "\n",
    "An index like `[30, 20]` selects a single element of an array, but we can select whole sections as well. For example, we can select the first ten days (columns) of values for the first four (rows) patients like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[0:4, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slice `0:4` means, \"Start at index 0 and go up to, but not including, index 4.\" Again, the up-to-but-not-including takes a bit of getting used to, but the rule is that the difference between the upper and lower bounds is the number of values in the slice.\n",
    "\n",
    "We don't have to start slices at 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[5:10, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also don't have to include the upper and lower bound on the slice. If we don't include the lower bound, Python uses 0 by default; if we don't include the upper, the slice runs to the end of the axis, and if we don't include either (i.e., if we just use ':' on its own), the slice includes everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small = data[:3, 36:]\n",
    "print('small is:')\n",
    "print(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays also know how to perform common mathematical operations on their values. The simplest operations with data are arithmetic: add, subtract, multiply, and divide. When you do such operations on arrays, the operation is done on each individual element of the array. Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doubledata = data * 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will create a new array `doubledata` whose elements have the value of two times the value of the corresponding elements in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('original:')\n",
    "print(data[:3, 36:])\n",
    "print('doubledata:')\n",
    "print(doubledata[:3, 36:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, instead of taking an array and doing arithmetic with a single value (as above) you did the arithmetic operation with another array of the same size and shape, the operation will be done on corresponding elements of the two arrays. Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripledata = doubledata + data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will give you an array where `tripledata[0,0]` will equal `doubledata[0,0]` plus `data[0,0]`, and so on for all other elements of the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('tripledata:')\n",
    "print(tripledata[:3, 36:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise A - square root\n",
    "\n",
    "Calculate the square root of the data using `numpy`. \n",
    "Print the result for the first 5 columns of the first 3 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics\n",
    "\n",
    "Often, we want to do more than add, subtract, multiply, and divide values of data. Arrays also know how to do more complex operations on their values. If we want to find the average inflammation for all patients on all days, for example, we can just ask the array for its mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mean` is a method of the array, i.e., a function that belongs to it in the same way that the member shape does. If variables are nouns, methods are verbs: they are what the thing in question knows how to do. This is why `data.shape` doesn't need to be called (it's just a thing) but `data.mean()` does (it's an action). It is also why we need empty parentheses for `ata.mean()`: even when we're not passing in any parameters, parentheses are how we tell Python to go and do something for us.\n",
    "\n",
    "NumPy arrays have lots of useful methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('maximum inflammation:', data.max())\n",
    "print('minimum inflammation:', data.min())\n",
    "print('standard deviation:', data.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing data, though, we often want to look at partial statistics, such as the maximum value per patient or the average value per day. One way to do this is to select the data we want to create a new temporary array, then ask it to do the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patient_0 = data[0, :] # 0 on the first axis, everything on the second\n",
    "print('maximum inflammation for patient 0:', patient_0.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we need the maximum inflammation for all patients, or the average for each day? As the diagram below shows, we want to perform the operation across an axis:\n",
    "![axis example](http://swcarpentry.github.io/python-novice-inflammation/fig/python-operations-across-axes.svg)\n",
    "To support this, most array methods allow us to specify the axis we want to work on. If we ask for the average across axis 0, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, we can ask this array what its shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.mean(axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `(40,)` tells us we have an NÃ—1 vector, so this is the average inflammation per day for all patients. If we average across axis 1, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is the average inflammation per patient across all days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise B - sum\n",
    "\n",
    "On which day did each patient had the most inflammation?\n",
    "Use `data.argmax` to find out.\n",
    "\n",
    "That means: we want to get a vector, so that in position _i_ we have the day in which patient _i_ (counting from 0) has the biggest measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "The mathematician [Richard Hamming](http://en.wikipedia.org/wiki/Richard_Hamming) once said, **\"The purpose of computing is insight, not numbers\"**, and the best way to develop insight is often to visualize data. Visualization deserves an entire lecture (or course) of its own, but we can explore a few features of Python's `matplotlib` here. While there is no \"official\" plotting library, this package is the _de facto_ standard. First, let's tell the IPython Notebook that we want our plots displayed inline, rather than in a separate viewing window. This command will also import many other useful scientific python functions and modules, including NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%` at the start of the line signals that this is a command for the _notebook_, rather than a statement in Python. \n",
    "\n",
    "Next, use two of `matplotlib`'s functions to create and display a heat map of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue regions in this heat map are low values, while red shows high values. As we can see, inflammation rises and falls over a 40-day period (The `;` at the end of the line supresses the automatic printing of function's return value, which is an `AxesImage` in this case).\n",
    "\n",
    "Let's take a look at the average inflammation over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_inflammation = data.mean(axis=0)\n",
    "print(avg_inflammation.shape)\n",
    "plot(avg_inflammation);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we put the average per day across all patients in the variable `avg_inflammation`, then used `plot` to create and display a line graph of those values. Let's have a look at two other statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(avg_inflammation, label='avg')\n",
    "plot(data.max(axis=0), label='max')\n",
    "plot(data.min(axis=0), label='min')\n",
    "\n",
    "# we can add some more features to the plot:\n",
    "title('inflammation per day')\n",
    "xlabel('day')\n",
    "ylabel('inflammation')\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib` has many more plotting commands. For example, we can do a scatter plot to see the how the measurements correlate between two patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patient1 = data[0, :] #the first row of data\n",
    "patient2 = data[1, :] #the second row of data\n",
    "scatter(patient1, patient2)\n",
    "xlabel(\"patient1\")\n",
    "ylabel(\"patient2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to know the distribution of parients that reacted to the treatment at a given date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day_n = 20 #let's select the 21st day\n",
    "patients_inflammation_for_day_n = data[:,day_n]\n",
    "hist(patients_inflammation_for_day_n);\n",
    "axvline(sum(patients_inflammation_for_day_n)/len(patients_inflammation_for_day_n), color='k');\n",
    "xlabel(\"inflammation value at day \" + str(day_n))\n",
    "ylabel(\"#patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise C\n",
    "\n",
    "In exercise B we calculated the day in which each patient had the most inflammation.\n",
    "Let's plot it now - make a scatter plot using the `scatter` command, with patient number on x-axis and day of max inflammation on y-axis.\n",
    "Don't forget to add axis labels with `xlabel` and `ylabel`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Life History Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times we want to display data with some smoothing or fitting of a regression line over it.\n",
    "To do this, we will use the _pandas_ and _seaborn_ library.\n",
    "_pandas_ is a very strong library for manipulation large datasets. _seaborn_ adds on top of _pandas_ a set of sophisticated statistical visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\") # control the plotting style\n",
    "sns.set_context(\"talk\") # set to talk because this is a lecture! hit shift-tab after the \"(\" to see other options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze animal life-history data from [AnAge](http://genomics.senescence.info/download.html#anage). \n",
    "We will get the data from the download page, but it's compressed with zip so we need to unzip it and then we can read the data using _pandas_ `read_table` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('http://genomics.senescence.info/species/dataset.zip', 'anage_dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('anage_dataset.zip') as z:\n",
    "    f = z.open('anage_data.txt')\n",
    "    data = pd.read_table(f)\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pandas_ holds data in `DataFrame` (similar to _R_).\n",
    "`DataFrame` have a single row per observation (in contrast to the previous exercise in which each table cell was one observation), and each column has a single variable. Variables can be numbers or strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` has many of the features of `numpy.ndarray` - it also has a `shape` and various statistical methods (`max`, `mean` etc.).\n",
    "However, `DataFrame` allows richer indexing.\n",
    "For example, let's browse our data for species that have body mass greater than 300 kg.\n",
    "First we will a new column that tells us if a row is a large animal row or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_index = data['Body mass (g)'] > 300*1000 # 300 kg\n",
    "print(large_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows for each row __True__ if the body mass is greater than 300kg and else __False__.\n",
    "\n",
    "Now, we slice or data with this boolean index. \n",
    "The `iterrows` method let's us iterate over the rows of the data. Note that it will skip over the False rows, because we apply iterrows to large_index.\n",
    "\n",
    "For each row we get both the row as a `Series` object (similar to `dict` for our use)\n",
    "and the row number as an `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_data = data[large_index]\n",
    "for i,row in large_data.iterrows(): \n",
    "    print(row['Common name'], row['Body mass (g)']/1000, 'kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... a [Dromedary](http://en.wikipedia.org/wiki/Dromedary) is a Camel.\n",
    "\n",
    "Let's continue with small and medium animals. For starters, let's plot a scatter of Body mass vs. Metabolic rate.\n",
    "Because we work with _pandas_, we can do that with the `plot` method of `DataFrame`, specifying the columns for `x` and `y` and a plotting style (without the style we would get a line plot which makes no sense here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[data['Body mass (g)'] < 3e5] \n",
    "data.plot(x='Body mass (g)', y='Metabolic rate (W)', style='o')\n",
    "ylabel('Metabolic rate (W)')\n",
    "sns.despine(offset=10)\n",
    "ylim(0, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.despine` removes the upper and right axes and the additional `offset` keyword creates a space between the plot and the axis.\n",
    "\n",
    "From this plot it seems that 1) there is a correlation between body mass and metabolic rate, and 2) there are many small animals (less than 30 kg) and not many medium animals (between 50 and 300 kg).\n",
    "\n",
    "Before we continue, I prefer to have mass in kg, let's add a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Body mass (kg)'] = data['Body mass (g)']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check how many records we have for each Class (as in the taxonomic unit): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_counts = data.Class.value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_counts.plot(kind='bar')\n",
    "ylabel('# species')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have lots of mammals and birds, and a few reptiles and amphibians. This is important as amphibian and reptiles could have a different replationship between mass and metabolism.\n",
    "\n",
    "Let's do a simple linear regression plot; but let's do it in separate for each Class. This is done using _seaborn_'s `lmplot` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Body mass (kg)', y='Metabolic rate (W)', data=data, hue='Class', ci=False, size=6, legend_out=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `hue` means _color_, but it also causes _seaborn_ to fit a different linear model to each of the Classes. \n",
    "As for the last 3 paramteres:\n",
    "- `ci` controls the confidence intervals. I chose `False`, but setting it to `True` will show them.\n",
    "- `size` controls the size of the plot\n",
    "- `legend_out` decides if the legend is inside the plot or outside. We have enough space for it in the left corner.\n",
    "\n",
    "We can see that mammals and birds have a clear correlation between size and metabolism and that it extends over a nice range of mass, so let's stick to mammals; next up we will see which Orders of mammals we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mammalia = data[data.Class=='Mammalia']\n",
    "order_counts = mammalia.Order.value_counts()\n",
    "ax=order_counts.plot(kind='bar')\n",
    "ylabel('# species')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see we have alot of rodents and carnivores, but also a good number of bats (_Chiroptera_) and primates.\n",
    "\n",
    "Let's continue only with orders that have at least 20 species - this also includes some cool marsupials like Kangaroo, Koala and [Taz](http://upload.wikimedia.org/wikipedia/en/c/c4/Taz-Looney_Tunes.svg) (Diprotodontia and Dasyuromorphia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orders = order_counts[order_counts >= 20]\n",
    "print(orders)\n",
    "abund_mammalia = mammalia[mammalia.Order.isin(orders.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Body mass (kg)', y='Metabolic rate (W)', data=abund_mammalia, hue=\"Order\", \n",
    "           ci=False, size=8, legend_out=False, line_kws={'lw':2}, scatter_kws={'s':50, 'alpha':0.5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is alot of data here I made the lines thinner - this can be done by giving _matplotlib_ keywords as a dictionary to the argument `line_kws` - and I made the markers bigger but with alpha (transperancy) 0.5 using the `scatter_kws` argument.\n",
    "\n",
    "Still ,there's too much data, and part of the problem is that some Orders are large - primates - and some are small - rodents.\n",
    "Let's plot a separate plot for each Order. We do this using the `col` and `row` arguments of `lmplot`, but in general this can be done for any plot using [_seaborn_'s `FacetGrid` function](http://stanford.edu/~mwaskom/software/seaborn/tutorial/axis_grids.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Body mass (kg)', y='Metabolic rate (W)', data=abund_mammalia, hue=\"Order\", \n",
    "           col=\"Order\", col_wrap=3, ci=None, scatter_kws={'s':40}, sharex=False, sharey=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the `sharex=False` and `sharey=False` arguments so that each Order will have a different axis range and so the data is will spread nicely.\n",
    "Last but not least, let's have a closer look at the corelation between mass and metabolism in primates. \n",
    "We will do a joint plot which will give us the pearson correlation and the distribution of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "primates = mammalia[mammalia.Order == 'Primates']\n",
    "print(sorted(primates[\"Common name\"]))\n",
    "sns.jointplot(x='Body mass (kg)', y='Metabolic rate (W)', data=primates, kind='reg', size=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More\n",
    "\n",
    "- Slides: [Statistical inference with Python](https://docs.google.com/presentation/d/1imQAEmNg4GB3bCAblauMOOLlAC95-XvkTSKB1_dB3Tg/pub?slide=id.p) by Allen Downey\n",
    "- Book: [Think Stats](greenteapress.com/thinkstats2/html/index.html) by Allen Downey - statistics with Python. Free Ebook.\n",
    "- Blog post: [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Slides: [Losing your loops](https://speakerdeck.com/jakevdp/losing-your-loops-fast-numerical-computing-with-numpy-pycon-2015): Fast numerical computing with NumPy\n",
    "- Notebooks: [Long Matplotlib tutorial](http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb), [IPython-Matplotlib gallery](https://github.com/rasbt/matplotlib-gallery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin\n",
    "This notebook is part of the _Python Programming for Life Sciences Graduate Students_ course given in Tel-Aviv University, Spring 2015.\n",
    "\n",
    "The notebook was written using [Python](http://pytho.org/) 3.5.1 and [IPython](http://ipython.org/) 2.5.0 (download from [PyZo](http://www.pyzo.org/downloads.html)).\n",
    "\n",
    "The code is available at https://github.com//Py4Life/TAU2016/blob/master/lecture8_dataAnalysis.ipynb.\n",
    "\n",
    "The notebook can be viewed online at http://nbviewer.ipython.org/github//Py4Life/TAU2016/blob/master/lecture8_dataAnalysis.ipynb.\n",
    "\n",
    "The notebook is also available as a PDF at https://github.com/Py4Life/TAU2015/blob/master/lecture8_dataAnalysis.pdf?raw=true.\n",
    "\n",
    "This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.\n",
    "\n",
    "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
